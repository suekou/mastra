# Mastra

> Mastra is an open-source TypeScript agent framework designed to provide the essential primitives for building AI applications. It enables developers to create AI agents with memory and tool-calling capabilities, implement deterministic LLM workflows, and leverage RAG for knowledge integration. With features like model routing, workflow graphs, and automated evals, Mastra provides a complete toolkit for developing, testing, and deploying AI applications.

This documentation covers everything from getting started to advanced features, APIs, and best practices for working with Mastra's agent-based architecture.

The documentation is organized into key sections:
- **docs**: Core documentation covering concepts, features, and implementation details
- **examples**: Practical examples and use cases demonstrating Mastra's capabilities
- **showcase**: A showcase of applications built using Mastra

Each section contains detailed markdown files that provide comprehensive information about Mastra's features and how to use them effectively.


## docs
- [Creating and Calling Agents | Agent Documentation | Mastra](https://mastra.ai/docs/agents/00-overview): Overview of agents in Mastra, detailing their capabilities and how they interact with tools, workflows, and external systems.
- [Using Agent Memory | Agents | Mastra Docs](https://mastra.ai/docs/agents/01-agent-memory): Documentation on how agents in Mastra use memory to store conversation history and contextual information.
- [Agent Tool Selection | Agent Documentation | Mastra](https://mastra.ai/docs/agents/02-adding-tools): Tools are typed functions that can be executed by agents or workflows, with built-in integration access and parameter validation. Each tool has a schema that defines its inputs, an executor function that implements its logic, and access to configured integrations.
- [03-adding-voice](https://mastra.ai/docs/agents/03-adding-voice)
- [Deployment](https://mastra.ai/docs/deployment/deployment): Build and deploy Mastra applications using platform-specific deployers or standard HTTP servers
- [Logging and Tracing | Mastra Deployment Documentation](https://mastra.ai/docs/deployment/logging-and-tracing): Documentation on effective logging and tracing in Mastra, crucial for understanding application behavior and improving AI accuracy.
- [MastraServer](https://mastra.ai/docs/deployment/server): Configure and customize the Mastra server with middleware and other options
- [Overview](https://mastra.ai/docs/evals/00-overview): Mastra evals help you measure LLM output quality with metrics for relevance, bias, hallucination, and more.
- [Supported evals](https://mastra.ai/docs/evals/01-supported-evals): Mastra provides several default evals for assessing Agent outputs.
- [Create your own Eval](https://mastra.ai/docs/evals/02-custom-eval): Mastra allows so create your own evals, here is how.
- [Licensing](https://mastra.ai/docs/faq): Mastra License
- [Getting started with Mastra and NextJS | Mastra Guides](https://mastra.ai/docs/frameworks/01-next-js): Guide on integrating Mastra with NextJS.
- [AI SDK](https://mastra.ai/docs/frameworks/02-ai-sdk): Learn how Mastra leverages the AI SDK library and how you can leverage it further with Mastra
- [Installing Mastra Locally | Getting Started | Mastra Docs](https://mastra.ai/docs/getting-started/installation): Guide on installing Mastra and setting up the necessary prerequisites for running it with various LLM providers.
- [Local Project Structure | Getting Started | Mastra Docs](https://mastra.ai/docs/getting-started/project-structure): Guide on organizing folders and files in Mastra, including best practices and recommended structures.
- [Building an AI Chef Assistant | Mastra Agent Guides](https://mastra.ai/docs/guides/01-chef-michel): Guide on creating a Chef Assistant agent in Mastra to help users cook meals with available ingredients.
- [Building an AI Stock Agent | Mastra Agents | Guides](https://mastra.ai/docs/guides/02-stock-agent): Guide on creating a simple stock agent in Mastra to fetch the last days closing stock price for a given symbol.
- [Building an AI Recruiter | Mastra Workflows | Guides](https://mastra.ai/docs/guides/03-recruiter): Guide on building a recruiter workflow in Mastra to gather and process candidate information using LLMs.
- [Introduction | Mastra Docs](https://mastra.ai/docs): Mastra is a TypeScript agent framework. It helps you build AI applications and features quickly. It gives you the set of primitives you need: workflows, agents, RAG, integrations, syncs and evals.
- [Creating Mastra Projects | Mastra Local Development Docs](https://mastra.ai/docs/local-dev/creating-projects): Initialize new Mastra projects or add Mastra to existing Node.js applications using the CLI
- [Using Mastra Integrations | Mastra Local Development Docs](https://mastra.ai/docs/local-dev/integrations): Documentation for Mastra integrations, which are auto-generated, type-safe API clients for third-party services.
- [Inspecting Agents with `mastra dev` | Mastra Local Dev Docs](https://mastra.ai/docs/local-dev/mastra-dev): Documentation for the mastra dev command, which launches a local development server for Mastra applications.
- [Chunking and Embedding Documents | RAG | Mastra Docs](https://mastra.ai/docs/rag/chunking-and-embedding): Guide on chunking and embedding documents in Mastra for efficient processing and retrieval.
- [RAG (Retrieval-Augmented Generation) in Mastra | Mastra Docs](https://mastra.ai/docs/rag/overview): Overview of Retrieval-Augmented Generation (RAG) in Mastra, detailing its capabilities for enhancing LLM outputs with relevant context.
- [Retrieval, Semantic Search, Reranking | RAG | Mastra Docs](https://mastra.ai/docs/rag/retrieval): Guide on retrieval processes in Mastras RAG systems, including semantic search, filtering, and re-ranking.
- [Storing Embeddings in A Vector Database | Mastra Docs](https://mastra.ai/docs/rag/vector-databases): Guide on vector storage options in Mastra, including embedded and dedicated vector databases for similarity search.
- [Reference: createTool() | Tools | Agents | Mastra Docs](https://mastra.ai/docs/reference/agents/createTool): Documentation for the createTool function in Mastra, which creates custom tools for agents and workflows.
- [Reference: Agent.generate() | Agents | Mastra Docs](https://mastra.ai/docs/reference/agents/generate): Documentation for the `.generate()` method in Mastra agents, which produces text or structured responses.
- [Reference: getAgent() | Agent Config | Agents | Mastra Docs](https://mastra.ai/docs/reference/agents/getAgent): API Reference for getAgent.
- [Reference: Agent.stream() | Streaming | Agents | Mastra Docs](https://mastra.ai/docs/reference/agents/stream): Documentation for the `.stream()` method in Mastra agents, which enables real-time streaming of responses.
- [mastra build](https://mastra.ai/docs/reference/cli/build): Build your Mastra project for production deployment
- [`mastra deploy` Reference | Deployment | Mastra CLI](https://mastra.ai/docs/reference/cli/deploy): Documentation for the mastra deploy command, which deploys Mastra projects to platforms like Vercel and Cloudflare.
- [`mastra dev` Reference | Local Development | Mastra CLI](https://mastra.ai/docs/reference/cli/dev): Documentation for the mastra dev command, which starts a development server for agents, tools, and workflows.
- [`mastra init` reference | Project Creation | Mastra CLI](https://mastra.ai/docs/reference/cli/init): Documentation for the mastra init command, which creates a new Mastra project with interactive setup options.
- [agents](https://mastra.ai/docs/reference/client-js/agents)
- [error-handling](https://mastra.ai/docs/reference/client-js/error-handling)
- [Mastra Client SDK](https://mastra.ai/docs/reference/client-js): A simple and type-safe interface to interact with Mastra REST APIs from TypeScript and JavaScript applications.
- [logs](https://mastra.ai/docs/reference/client-js/logs)
- [memory](https://mastra.ai/docs/reference/client-js/memory)
- [telemetry](https://mastra.ai/docs/reference/client-js/telemetry)
- [tools](https://mastra.ai/docs/reference/client-js/tools)
- [vectors](https://mastra.ai/docs/reference/client-js/vectors)
- [workflows](https://mastra.ai/docs/reference/client-js/workflows)
- [Mastra Core](https://mastra.ai/docs/reference/core/mastra-class): Documentation for the Mastra Class, the core entry point for managing agents, workflows, and server endpoints.
- [Cloudflare Deployer](https://mastra.ai/docs/reference/deployer/cloudflare): Documentation for the CloudflareDeployer class, which deploys Mastra applications to Cloudflare Workers.
- [Mastra Deployer](https://mastra.ai/docs/reference/deployer/deployer): Documentation for the Deployer abstract class, which handles packaging and deployment of Mastra applications.
- [Netlify Deployer](https://mastra.ai/docs/reference/deployer/netlify): Documentation for the NetlifyDeployer class, which deploys Mastra applications to Netlify Functions.
- [Vercel Deployer](https://mastra.ai/docs/reference/deployer/vercel): Documentation for the VercelDeployer class, which deploys Mastra applications to Vercel.
- [Reference: Answer Relevancy | Metrics | Evals | Mastra Docs](https://mastra.ai/docs/reference/evals/answer-relevancy): Documentation for the Answer Relevancy Metric in Mastra, which evaluates how well LLM outputs address the input query.
- [Reference: Bias | Output Metrics | Evals | Mastra Docs](https://mastra.ai/docs/reference/evals/bias): Documentation for the Bias Metric in Mastra, which evaluates LLM outputs for various forms of bias, including gender, political, racial/ethnic, or geographical bias.
- [Reference: Completeness | Metrics | Evals | Mastra Docs](https://mastra.ai/docs/reference/evals/completeness): Documentation for the Completeness Metric in Mastra, which evaluates how thoroughly LLM outputs cover key elements present in the input.
- [Reference: Content Similarity | Evals | Mastra Docs](https://mastra.ai/docs/reference/evals/content-similarity): Documentation for the Content Similarity Metric in Mastra, which measures textual similarity between strings and provides a matching score.
- [Reference: Context Position | Metrics | Evals | Mastra Docs](https://mastra.ai/docs/reference/evals/context-position): Documentation for the Context Position Metric in Mastra, which evaluates the ordering of context nodes based on their relevance to the query and output.
- [Reference: Context Precision | Metrics | Evals | Mastra Docs](https://mastra.ai/docs/reference/evals/context-precision): Documentation for the Context Precision Metric in Mastra, which evaluates the relevance and precision of retrieved context nodes for generating expected outputs.
- [Reference: Context Relevancy | Evals | Mastra Docs](https://mastra.ai/docs/reference/evals/context-relevancy): Documentation for the Context Relevancy Metric, which evaluates the relevance of retrieved context in RAG pipelines.
- [Reference: Contextual Recall | Metrics | Evals | Mastra Docs](https://mastra.ai/docs/reference/evals/contextual-recall): Documentation for the Contextual Recall Metric, which evaluates the completeness of LLM responses in incorporating relevant context.
- [Reference: Faithfulness | Metrics | Evals | Mastra Docs](https://mastra.ai/docs/reference/evals/faithfulness): Documentation for the Faithfulness Metric in Mastra, which evaluates the factual accuracy of LLM outputs compared to the provided context.
- [Reference: Hallucination | Metrics | Evals | Mastra Docs](https://mastra.ai/docs/reference/evals/hallucination): Documentation for the Hallucination Metric in Mastra, which evaluates the factual correctness of LLM outputs by identifying contradictions with provided context.
- [Reference: Keyword Coverage | Metrics | Evals | Mastra Docs](https://mastra.ai/docs/reference/evals/keyword-coverage): Documentation for the Keyword Coverage Metric in Mastra, which evaluates how well LLM outputs cover important keywords from the input.
- [Reference: Prompt Alignment | Metrics | Evals | Mastra Docs](https://mastra.ai/docs/reference/evals/prompt-alignment): Documentation for the Prompt Alignment Metric in Mastra, which evaluates how well LLM outputs adhere to given prompt instructions.
- [Reference: Summarization | Metrics | Evals | Mastra Docs](https://mastra.ai/docs/reference/evals/summarization): Documentation for the Summarization Metric in Mastra, which evaluates the quality of LLM-generated summaries for content and factual accuracy.
- [Reference: Textual Difference | Evals | Mastra Docs](https://mastra.ai/docs/reference/evals/textual-difference): Documentation for the Textual Difference Metric in Mastra, which measures textual differences between strings using sequence matching.
- [Reference: Tone Consistency | Metrics | Evals | Mastra Docs](https://mastra.ai/docs/reference/evals/tone-consistency): Documentation for the Tone Consistency Metric in Mastra, which evaluates emotional tone and sentiment consistency in text.
- [Reference: Toxicity | Metrics | Evals | Mastra Docs](https://mastra.ai/docs/reference/evals/toxicity): Documentation for the Toxicity Metric in Mastra, which evaluates LLM outputs for racist, biased, or toxic elements.
- [API Reference](https://mastra.ai/docs/reference): Mastra API Reference
- [Memory](https://mastra.ai/docs/reference/memory/Memory)
- [createThread](https://mastra.ai/docs/reference/memory/createThread)
- [getThreadById](https://mastra.ai/docs/reference/memory/getThreadById)
- [getThreadsByResourceId](https://mastra.ai/docs/reference/memory/getThreadsByResourceId)
- [query](https://mastra.ai/docs/reference/memory/query)
- [Reference: createLogger() | Mastra Observability Docs](https://mastra.ai/docs/reference/observability/create-logger): Documentation for the createLogger function, which instantiates a logger based on a given configuration.
- [Reference: Logger Instance | Mastra Observability Docs](https://mastra.ai/docs/reference/observability/logger): Documentation for Logger instances, which provide methods to record events at various severity levels.
- [Reference: OtelConfig | Mastra Observability Docs](https://mastra.ai/docs/reference/observability/otel-config): Documentation for the OtelConfig object, which configures OpenTelemetry instrumentation, tracing, and exporting behavior.
- [Reference: Braintrust | Observability | Mastra Docs](https://mastra.ai/docs/reference/observability/providers/braintrust): Documentation for integrating Braintrust with Mastra, an evaluation and monitoring platform for LLM applications.
- [Reference: Provider List | Observability | Mastra Docs](https://mastra.ai/docs/reference/observability/providers): Overview of observability providers supported by Mastra, including SigNoz, Braintrust, Langfuse, and more.
- [Reference: Laminar Integration | Mastra Observability Docs](https://mastra.ai/docs/reference/observability/providers/laminar): Documentation for integrating Laminar with Mastra, a specialized observability platform for LLM applications.
- [Reference: Langfuse Integration | Mastra Observability Docs](https://mastra.ai/docs/reference/observability/providers/langfuse): Documentation for integrating Langfuse with Mastra, an open-source observability platform for LLM applications.
- [Reference: LangSmith Integration | Mastra Observability Docs](https://mastra.ai/docs/reference/observability/providers/langsmith): Documentation for integrating LangSmith with Mastra, a platform for debugging, testing, evaluating, and monitoring LLM applications.
- [Reference: LangWatch Integration | Mastra Observability Docs](https://mastra.ai/docs/reference/observability/providers/langwatch): Documentation for integrating LangWatch with Mastra, a specialized observability platform for LLM applications.
- [Reference: New Relic Integration | Mastra Observability Docs](https://mastra.ai/docs/reference/observability/providers/new-relic): Documentation for integrating New Relic with Mastra, a comprehensive observability platform supporting OpenTelemetry for full-stack monitoring.
- [Reference: SigNoz Integration | Mastra Observability Docs](https://mastra.ai/docs/reference/observability/providers/signoz): Documentation for integrating SigNoz with Mastra, an open-source APM and observability platform providing full-stack monitoring through OpenTelemetry.
- [Reference: Traceloop Integration | Mastra Observability Docs](https://mastra.ai/docs/reference/observability/providers/traceloop): Documentation for integrating Traceloop with Mastra, an OpenTelemetry-native observability platform for LLM applications.
- [Reference: Astra Vector Store | Vector Databases | RAG | Mastra Docs](https://mastra.ai/docs/reference/rag/astra): Documentation for the AstraVector class in Mastra, which provides vector search using DataStax Astra DB.
- [Reference: Chroma Vector Store | Vector Databases | RAG | Mastra Docs](https://mastra.ai/docs/reference/rag/chroma): Documentation for the ChromaVector class in Mastra, which provides vector search using ChromaDB.
- [Reference: .chunk() | Document Processing | RAG | Mastra Docs](https://mastra.ai/docs/reference/rag/chunk): Documentation for the chunk function in Mastra, which splits documents into smaller segments using various strategies.
- [Reference: MDocument | Document Processing | RAG | Mastra Docs](https://mastra.ai/docs/reference/rag/document): Documentation for the MDocument class in Mastra, which handles document processing and chunking.
- [Reference: embed() | Document Embedding | RAG | Mastra Docs](https://mastra.ai/docs/reference/rag/embeddings): Documentation for embedding functionality in Mastra using the AI SDK.
- [Reference: ExtractParams | Document Processing | RAG | Mastra Docs](https://mastra.ai/docs/reference/rag/extract-params): Documentation for metadata extraction configuration in Mastra.
- [Reference: GraphRAG | Graph-based RAG | RAG | Mastra Docs](https://mastra.ai/docs/reference/rag/graph-rag): Documentation for the GraphRAG class in Mastra, which implements a graph-based approach to retrieval augmented generation.
- [Default Vector Store | Vector Databases | RAG | Mastra Docs](https://mastra.ai/docs/reference/rag/libsql): Documentation for the LibSQLVector class in Mastra, which provides vector search using LibSQL with vector extensions.
- [Reference: Metadata Filters | Metadata Filtering | RAG | Mastra Docs](https://mastra.ai/docs/reference/rag/metadata-filters): Documentation for metadata filtering capabilities in Mastra, which allow for precise querying of vector search results across different vector stores.
- [Reference: PG Vector Store | Vector Databases | RAG | Mastra Docs](https://mastra.ai/docs/reference/rag/pg): Documentation for the PgVector class in Mastra, which provides vector search using PostgreSQL with pgvector extension.
- [Reference: Pinecone Vector Store | Vector DBs | RAG | Mastra Docs](https://mastra.ai/docs/reference/rag/pinecone): Documentation for the PineconeVector class in Mastra, which provides an interface to Pinecones vector database.
- [Reference: Qdrant Vector Store | Vector Databases | RAG | Mastra Docs](https://mastra.ai/docs/reference/rag/qdrant): Documentation for integrating Qdrant with Mastra, a vector similarity search engine for managing vectors and payloads.
- [Reference: Rerank | Document Retrieval | RAG | Mastra Docs](https://mastra.ai/docs/reference/rag/rerank): Documentation for the rerank function in Mastra, which provides advanced reranking capabilities for vector search results.
- [Reference: Turbopuffer Vector Store | Vector Databases | RAG | Mastra Docs](https://mastra.ai/docs/reference/rag/turbopuffer): Documentation for integrating Turbopuffer with Mastra, a high-performance vector database for efficient similarity search.
- [Reference: Upstash Vector Store | Vector Databases | RAG | Mastra Docs](https://mastra.ai/docs/reference/rag/upstash): Documentation for the UpstashVector class in Mastra, which provides vector search using Upstash Vector.
- [Reference: Cloudflare Vector Store | Vector Databases | RAG | Mastra Docs](https://mastra.ai/docs/reference/rag/vectorize): Documentation for the CloudflareVector class in Mastra, which provides vector search using Cloudflare Vectorize.
- [LibSQL Storage | Storage System | Mastra Core](https://mastra.ai/docs/reference/storage/libsql): Documentation for the LibSQL storage implementation in Mastra.
- [PostgreSQL Storage | Storage System | Mastra Core](https://mastra.ai/docs/reference/storage/postgresql): Documentation for the PostgreSQL storage implementation in Mastra.
- [Upstash Storage | Storage System | Mastra Core](https://mastra.ai/docs/reference/storage/upstash): Documentation for the Upstash storage implementation in Mastra.
- [Reference: MastraMCPClient | Tool Discovery | Mastra Docs](https://mastra.ai/docs/reference/tools/client): API Reference for MastraMCPClient - A client implementation for the Model Context Protocol.
- [Reference: createDocumentChunkerTool() | Tools | Mastra Docs](https://mastra.ai/docs/reference/tools/document-chunker-tool): Documentation for the Document Chunker Tool in Mastra, which splits documents into smaller chunks for efficient processing and retrieval.
- [Reference: createGraphRAGTool() | RAG | Mastra Tools Docs](https://mastra.ai/docs/reference/tools/graph-rag-tool): Documentation for the Graph RAG Tool in Mastra, which enhances RAG by building a graph of semantic relationships between documents.
- [Reference: MCPConfiguration | Tool Management | Mastra Docs](https://mastra.ai/docs/reference/tools/mcp-configuration): API Reference for MCPConfiguration - A class for managing multiple Model Context Protocol servers and their tools.
- [Reference: createVectorQueryTool() | RAG | Mastra Tools Docs](https://mastra.ai/docs/reference/tools/vector-query-tool): Documentation for the Vector Query Tool in Mastra, which facilitates semantic search over vector stores with filtering and reranking capabilities.
- [Reference: CompositeVoice | Voice Providers | Mastra Docs](https://mastra.ai/docs/reference/voice/composite-voice): Documentation for the CompositeVoice class, which enables combining multiple voice providers for flexible text-to-speech and speech-to-text operations.
- [Reference: Deepgram Voice | Voice Providers | Mastra Docs](https://mastra.ai/docs/reference/voice/deepgram): Documentation for the Deepgram voice implementation, providing text-to-speech and speech-to-text capabilities with multiple voice models and languages.
- [Reference: ElevenLabs Voice | Voice Providers | Mastra Docs](https://mastra.ai/docs/reference/voice/elevenlabs): Documentation for the ElevenLabs voice implementation, offering high-quality text-to-speech capabilities with multiple voice models and natural-sounding synthesis.
- [Reference: Google Voice | Voice Providers | Mastra Docs](https://mastra.ai/docs/reference/voice/google): Documentation for the Google Voice implementation, providing text-to-speech and speech-to-text capabilities.
- [Reference: MastraVoice | Voice Providers | Mastra Docs](https://mastra.ai/docs/reference/voice/mastra-voice): Documentation for the MastraVoice abstract base class, which defines the core interface for all voice services in Mastra, including speech-to-speech capabilities.
- [Reference: Murf Voice | Voice Providers | Mastra Docs](https://mastra.ai/docs/reference/voice/murf): Documentation for the Murf voice implementation, providing text-to-speech capabilities.
- [Reference: OpenAI Realtime Voice | Voice Providers | Mastra Docs](https://mastra.ai/docs/reference/voice/openai-realtime): Documentation for the OpenAIRealtimeVoice class, providing real-time text-to-speech and speech-to-text capabilities via WebSockets.
- [Reference: OpenAI Voice | Voice Providers | Mastra Docs](https://mastra.ai/docs/reference/voice/openai): Documentation for the OpenAIVoice class, providing text-to-speech and speech-to-text capabilities.
- [Reference: PlayAI Voice | Voice Providers | Mastra Docs](https://mastra.ai/docs/reference/voice/playai): Documentation for the PlayAI voice implementation, providing text-to-speech capabilities.
- [Reference: Speechify Voice | Voice Providers | Mastra Docs](https://mastra.ai/docs/reference/voice/speechify): Documentation for the Speechify voice implementation, providing text-to-speech capabilities.
- [Reference: .after() | Building Workflows | Mastra Docs](https://mastra.ai/docs/reference/workflows/after): Documentation for the `after()` method in workflows, enabling branching and merging paths.
- [Reference: Workflow.commit() | Running Workflows | Mastra Docs](https://mastra.ai/docs/reference/workflows/commit): Documentation for the `.commit()` method in workflows, which re-initializes the workflow machine with the current step configuration.
- [Reference: Workflow.createRun() | Running Workflows | Mastra Docs](https://mastra.ai/docs/reference/workflows/createRun): Documentation for the `.createRun()` method in workflows, which initializes a new workflow run instance.
- [Reference: Workflow.else() | Conditional Branching | Mastra Docs](https://mastra.ai/docs/reference/workflows/else): Documentation for the `.else()` method in Mastra workflows, which creates an alternative branch when an if condition is false.
- [Reference: Workflow.execute() | Workflows | Mastra Docs](https://mastra.ai/docs/reference/workflows/execute): Documentation for the `.execute()` method in Mastra workflows, which runs workflow steps and returns results.
- [Reference: Workflow.if() | Conditional Branching | Mastra Docs](https://mastra.ai/docs/reference/workflows/if): Documentation for the `.if()` method in Mastra workflows, which creates conditional branches based on specified conditions.
- [Reference: Workflow.resume() | Running Workflows | Mastra Docs](https://mastra.ai/docs/reference/workflows/resume): Documentation for the `.resume()` method in workflows, which continues execution of a suspended workflow step.
- [Reference: start() | Running Workflows | Mastra Docs](https://mastra.ai/docs/reference/workflows/start): Documentation for the `start()` method in workflows, which begins execution of a workflow run.
- [Reference: Step | Building Workflows | Mastra Docs](https://mastra.ai/docs/reference/workflows/step-class): Documentation for the Step class, which defines individual units of work within a workflow.
- [Reference: StepCondition | Building Workflows | Mastra](https://mastra.ai/docs/reference/workflows/step-condition): Documentation for the step condition class in workflows, which determines whether a step should execute based on the output of previous steps or trigger data.
- [Reference: Workflow.step() | Workflows | Mastra Docs](https://mastra.ai/docs/reference/workflows/step-function): Documentation for the `.step()` method in workflows, which adds a new step to the workflow.
- [Reference: StepOptions | Building Workflows | Mastra Docs](https://mastra.ai/docs/reference/workflows/step-options): Documentation for the step options in workflows, which control variable mapping, execution conditions, and other runtime behavior.
- [Reference: suspend() | Control Flow | Mastra Docs](https://mastra.ai/docs/reference/workflows/suspend): Documentation for the suspend function in Mastra workflows, which pauses execution until resumed.
- [Reference: Workflow.then() | Building Workflows | Mastra Docs](https://mastra.ai/docs/reference/workflows/then): Documentation for the `.then()` method in workflows, which creates sequential dependencies between steps.
- [Reference: Workflow.until() | Looping in Workflows | Mastra Docs](https://mastra.ai/docs/reference/workflows/until): Documentation for the `.until()` method in Mastra workflows, which repeats a step until a specified condition becomes true.
- [Reference: Workflow.watch() | Workflows | Mastra Docs](https://mastra.ai/docs/reference/workflows/watch): Documentation for the `.watch()` method in workflows, which monitors the status of a workflow run.
- [Reference: Workflow.while() | Looping in Workflows | Mastra Docs](https://mastra.ai/docs/reference/workflows/while): Documentation for the `.while()` method in Mastra workflows, which repeats a step as long as a specified condition remains true.
- [Reference: Workflow Class | Building Workflows | Mastra Docs](https://mastra.ai/docs/reference/workflows/workflow): Documentation for the Workflow class in Mastra, which enables you to create state machines for complex sequences of operations with conditional branching and data validation.
- [Handling Complex LLM Operations | Workflows | Mastra](https://mastra.ai/docs/workflows/00-overview): Workflows in Mastra help you orchestrate complex sequences of operations with features like branching, parallel execution, resource suspension, and more.
- [Branching, Merging, Conditions | Workflows | Mastra Docs](https://mastra.ai/docs/workflows/control-flow): Control flow in Mastra workflows allows you to manage branching, merging, and conditions to construct workflows that meet your logic requirements.
- [Data Flow Between Steps | Workflows | Mastra Docs](https://mastra.ai/docs/workflows/data-flow): Learn how to pass data between steps in Mastra workflows using variables, context, and getStepResult.
- [Dynamic Workflows | Mastra Docs](https://mastra.ai/docs/workflows/dynamic-workflows): Learn how to create dynamic workflows within workflow steps, allowing for flexible workflow creation based on runtime conditions.
- [Creating Steps and Adding to Workflows | Mastra Docs](https://mastra.ai/docs/workflows/steps): Steps in Mastra workflows provide a structured way to manage operations by defining inputs, outputs, and execution logic.
- [Suspend & Resume Workflows | Human-in-the-Loop | Mastra Docs](https://mastra.ai/docs/workflows/suspend-and-resume): Suspend and resume in Mastra workflows allows you to pause execution while waiting for external input or resources.
- [Data Mapping with Workflow Variables | Mastra Docs](https://mastra.ai/docs/workflows/variables): Learn how to use workflow variables to map data between steps and create dynamic data flows in your Mastra workflows.

## examples
- [Example: Adding Voice Capabilities | Agents | Mastra](https://mastra.ai/examples/agents/adding-voice-capabilities): Example of adding voice capabilities to Mastra agents, enabling them to speak and listen using different voice providers.
- [Example: Calling Agentic Workflows | Agents | Mastra Docs](https://mastra.ai/examples/agents/agentic-workflows): Example of creating AI workflows in Mastra, demonstrating integration of external APIs with LLM-powered planning.
- [Example: Categorizing Birds | Agents | Mastra Docs](https://mastra.ai/examples/agents/bird-checker): Example of using a Mastra AI Agent to determine if an image from Unsplash depicts a bird.
- [Example: Hierarchical Multi-Agent System | Agents | Mastra](https://mastra.ai/examples/agents/hierarchical-multi-agent): Example of creating a hierarchical multi-agent system using Mastra, where agents interact through tool functions.
- [Example: Multi-Agent Workflow | Agents | Mastra Docs](https://mastra.ai/examples/agents/multi-agent-workflow): Example of creating an agentic workflow in Mastra, where work product is passed between multiple agents.
- [Example: Agents with a System Prompt | Agents | Mastra Docs](https://mastra.ai/examples/agents/system-prompt): Example of creating an AI agent in Mastra with a system prompt to define its personality and capabilities.
- [Example: Giving an Agent a Tool | Agents | Mastra Docs](https://mastra.ai/examples/agents/using-a-tool): Example of creating an AI agent in Mastra that uses a dedicated tool to provide weather information.
- [Example: Answer Relevancy | Evals | Mastra Docs](https://mastra.ai/examples/evals/answer-relevancy): Example of using the Answer Relevancy metric to evaluate response relevancy to queries.
- [Example: Bias | Evals | Mastra Docs](https://mastra.ai/examples/evals/bias): Example of using the Bias metric to evaluate responses for various forms of bias.
- [Example: Completeness | Evals | Mastra Docs](https://mastra.ai/examples/evals/completeness): Example of using the Completeness metric to evaluate how thoroughly responses cover input elements.
- [Example: Content Similarity | Evals | Mastra Docs](https://mastra.ai/examples/evals/content-similarity): Example of using the Content Similarity metric to evaluate text similarity between content.
- [Example: Context Position | Evals | Mastra Docs](https://mastra.ai/examples/evals/context-position): Example of using the Context Position metric to evaluate sequential ordering in responses.
- [Example: Context Precision | Evals | Mastra Docs](https://mastra.ai/examples/evals/context-precision): Example of using the Context Precision metric to evaluate how precisely context information is used.
- [Example: Context Relevancy | Evals | Mastra Docs](https://mastra.ai/examples/evals/context-relevancy): Example of using the Context Relevancy metric to evaluate how relevant context information is to a query.
- [Example: Contextual Recall | Evals | Mastra Docs](https://mastra.ai/examples/evals/contextual-recall): Example of using the Contextual Recall metric to evaluate how well responses incorporate context information.
- [Example: Custom Eval | Evals | Mastra Docs](https://mastra.ai/examples/evals/custom-eval): Example of creating custom LLM-based evaluation metrics in Mastra.
- [Example: Faithfulness | Evals | Mastra Docs](https://mastra.ai/examples/evals/faithfulness): Example of using the Faithfulness metric to evaluate how factually accurate responses are compared to context.
- [Example: Hallucination | Evals | Mastra Docs](https://mastra.ai/examples/evals/hallucination): Example of using the Hallucination metric to evaluate factual contradictions in responses.
- [Example: Keyword Coverage | Evals | Mastra Docs](https://mastra.ai/examples/evals/keyword-coverage): Example of using the Keyword Coverage metric to evaluate how well responses cover important keywords from input text.
- [Example: Prompt Alignment | Evals | Mastra Docs](https://mastra.ai/examples/evals/prompt-alignment): Example of using the Prompt Alignment metric to evaluate instruction adherence in responses.
- [Example: Summarization | Evals | Mastra Docs](https://mastra.ai/examples/evals/summarization): Example of using the Summarization metric to evaluate how well LLM-generated summaries capture content while maintaining factual accuracy.
- [Example: Textual Difference | Evals | Mastra Docs](https://mastra.ai/examples/evals/textual-difference): Example of using the Textual Difference metric to evaluate similarity between text strings by analyzing sequence differences and changes.
- [Example: Tone Consistency | Evals | Mastra Docs](https://mastra.ai/examples/evals/tone-consistency): Example of using the Tone Consistency metric to evaluate emotional tone patterns and sentiment consistency in text.
- [Example: Toxicity | Evals | Mastra Docs](https://mastra.ai/examples/evals/toxicity): Example of using the Toxicity metric to evaluate responses for harmful content and toxic language.
- [Examples List: Workflows, Agents, RAG | Mastra Docs](https://mastra.ai/examples): Explore practical examples of AI development with Mastra, including text generation, RAG implementations, structured outputs, and multi-modal interactions. Learn how to build AI applications using OpenAI, Anthropic, and Google Gemini.
- [memory-with-libsql](https://mastra.ai/examples/memory/memory-with-libsql)
- [memory-with-pg](https://mastra.ai/examples/memory/memory-with-pg)
- [memory-with-upstash](https://mastra.ai/examples/memory/memory-with-upstash)
- [Streaming Working Memory (advanced)](https://mastra.ai/examples/memory/streaming-working-memory-advanced): Example of using working memory to maintain a todo list across conversations
- [Streaming Working Memory](https://mastra.ai/examples/memory/streaming-working-memory): Example of using working memory with an agent
- [Example: Adjusting Chunk Delimiters | RAG | Mastra Docs](https://mastra.ai/examples/rag/adjust-chunk-delimiters): Adjust chunk delimiters in Mastra to better match your content structure.
- [Example: Adjusting The Chunk Size | RAG | Mastra Docs](https://mastra.ai/examples/rag/adjust-chunk-size): Adjust chunk size in Mastra to better match your content and memory requirements.
- [Example: A Complete RAG System | RAG | Mastra Docs](https://mastra.ai/examples/rag/basic-rag): Example of implementing a basic RAG system in Mastra using OpenAI embeddings and PGVector for vector storage.
- [Example: Semantically Chunking HTML | RAG | Mastra Docs](https://mastra.ai/examples/rag/chunk-html): Chunk HTML content in Mastra to semantically chunk the document.
- [Example: Semantically Chunking JSON | RAG | Mastra Docs](https://mastra.ai/examples/rag/chunk-json): Chunk JSON data in Mastra to semantically chunk the document.
- [Example: Semantically Chunking Markdown | RAG | Mastra Docs](https://mastra.ai/examples/rag/chunk-markdown): Example of using Mastra to chunk markdown documents for search or retrieval purposes.
- [Example: Semantically Chunking Text | RAG | Mastra Docs](https://mastra.ai/examples/rag/chunk-text): Example of using Mastra to split large text documents into smaller chunks for processing.
- [Example: Optimizing Information Density | RAG | Mastra Docs](https://mastra.ai/examples/rag/cleanup-rag): Example of implementing a RAG system in Mastra to optimize information density and deduplicate data using LLM-based processing.
- [Example: Chain of Thought Prompting | RAG | Mastra Docs](https://mastra.ai/examples/rag/cot-rag): Example of implementing a RAG system in Mastra with chain-of-thought reasoning using OpenAI and PGVector.
- [Example: Chain of Thought Workflow | RAG | Mastra Docs](https://mastra.ai/examples/rag/cot-workflow-rag): Example of implementing a RAG system in Mastra with chain-of-thought reasoning using OpenAI and PGVector.
- [Example: Embedding Chunk Arrays | RAG | Mastra Docs](https://mastra.ai/examples/rag/embed-chunk-array): Example of using Mastra to generate embeddings for an array of text chunks for similarity search.
- [Example: Embedding Text Chunks | RAG | Mastra Docs](https://mastra.ai/examples/rag/embed-text-chunk): Example of using Mastra to generate an embedding for a single text chunk for similarity search.
- [Example: Embedding Text with Cohere | RAG | Mastra Docs](https://mastra.ai/examples/rag/embed-text-with-cohere): Example of using Mastra to generate embeddings using Coheres embedding model.
- [Example: Agent-Driven Metadata Filtering | Retrieval | RAG | Mastra Docs](https://mastra.ai/examples/rag/filter-rag): Example of using a Mastra agent in a RAG system to construct and apply metadata filters for document retrieval.
- [Example: A Complete Graph RAG System | RAG | Mastra Docs](https://mastra.ai/examples/rag/graph-rag): Example of implementing a Graph RAG system in Mastra using OpenAI embeddings and PGVector for vector storage.
- [Example: Hybrid Vector Search | RAG | Mastra Docs](https://mastra.ai/examples/rag/hybrid-vector-search): Example of using metadata filters with PGVector to enhance vector search results in Mastra.
- [Example: Insert Embeddings in Astra DB | RAG | Mastra Docs](https://mastra.ai/examples/rag/insert-embedding-in-astra): Example of using Mastra to store embeddings in Astra DB for similarity search.
- [Example: Insert Embeddings in Chroma | RAG | Mastra Docs](https://mastra.ai/examples/rag/insert-embedding-in-chroma): Example of using Mastra to store embeddings in Chroma for similarity search.
- [Example: Insert Embeddings in LibSQL | RAG | Mastra Docs](https://mastra.ai/examples/rag/insert-embedding-in-libsql): Example of using Mastra to store embeddings in LibSQL for similarity search.
- [Example: Insert Embeddings in PgVector | RAG | Mastra Docs](https://mastra.ai/examples/rag/insert-embedding-in-pgvector): Example of using Mastra to store embeddings in a PostgreSQL database with the pgvector extension for similarity search.
- [Example: Insert Embeddings in Pinecone | RAG | Mastra Docs](https://mastra.ai/examples/rag/insert-embedding-in-pinecone): Example of using Mastra to store embeddings in Pinecone for similarity search.
- [Example: Insert Embeddings in Qdrant | RAG | Mastra Docs](https://mastra.ai/examples/rag/insert-embedding-in-qdrant): Example of using Mastra to store embeddings in Qdrant for similarity search.
- [Example: Insert Embeddings in Upstash | RAG | Mastra Docs](https://mastra.ai/examples/rag/insert-embedding-in-upstash): Example of using Mastra to store embeddings in Upstash for similarity search.
- [Example: Insert Embeddings in Cloudflare Vectorize | RAG | Mastra Docs](https://mastra.ai/examples/rag/insert-embedding-in-vectorize): Example of using Mastra to store embeddings in Cloudflare Vectorize for similarity search.
- [Example: Metadata Extraction | Retrieval | RAG | Mastra Docs](https://mastra.ai/examples/rag/metadata-extraction): Example of extracting and utilizing metadata from documents in Mastra for enhanced document processing and retrieval.
- [Example: Re-ranking Results with Tools | Retrieval | RAG | Mastra Docs](https://mastra.ai/examples/rag/rerank-rag): Example of implementing a RAG system with re-ranking in Mastra using OpenAI embeddings and PGVector for vector storage.
- [Example: Re-ranking Results | Retrieval | RAG | Mastra Docs](https://mastra.ai/examples/rag/rerank): Example of implementing semantic re-ranking in Mastra using OpenAI embeddings and PGVector for vector storage.
- [Example: Reranking with Cohere | RAG | Mastra Docs](https://mastra.ai/examples/rag/reranking-with-cohere): Example of using Mastra to improve document retrieval relevance with Coheres reranking service.
- [Example: Retrieving Top-K Results | RAG | Mastra Docs](https://mastra.ai/examples/rag/retrieve-results): Example of using Mastra to query a vector database and retrieve semantically similar chunks.
- [Example: Branching Paths | Workflows | Mastra Docs](https://mastra.ai/examples/workflows/branching-paths): Example of using Mastra to create workflows with branching paths based on intermediate results.
- [Example: Calling an Agent from a Workflow | Mastra Docs](https://mastra.ai/examples/workflows/calling-agent): Example of using Mastra to call an AI agent from within a workflow step.
- [Example: Conditional Branching (experimental) | Workflows | Mastra Docs](https://mastra.ai/examples/workflows/conditional-branching): Example of using Mastra to create conditional branches in workflows using if/else statements.
- [Example: Creating a Workflow | Workflows | Mastra Docs](https://mastra.ai/examples/workflows/creating-a-workflow): Example of using Mastra to define and execute a simple workflow with a single step.
- [Example: Cyclical Dependencies | Workflows | Mastra Docs](https://mastra.ai/examples/workflows/cyclical-dependencies): Example of using Mastra to create workflows with cyclical dependencies and conditional loops.
- [Example: Parallel Execution | Workflows | Mastra Docs](https://mastra.ai/examples/workflows/parallel-steps): Example of using Mastra to execute multiple independent tasks in parallel within a workflow.
- [Example: Sequential Steps | Workflows | Mastra Docs](https://mastra.ai/examples/workflows/sequential-steps): Example of using Mastra to chain workflow steps in a specific sequence, passing data between them.
- [Example: Suspend and Resume | Workflows | Mastra Docs](https://mastra.ai/examples/workflows/suspend-and-resume): Example of using Mastra to suspend and resume workflow steps during execution.
- [Example: Using a Tool as a Step | Workflows | Mastra Docs](https://mastra.ai/examples/workflows/using-a-tool-as-a-step): Example of using Mastra to integrate a custom tool as a step in a workflow.
- [Data Mapping with Workflow Variables | Mastra Examples](https://mastra.ai/examples/workflows/workflow-variables): Learn how to use workflow variables to map data between steps in Mastra workflows.

## showcase
- [Showcase](https://mastra.ai/showcase): Check out these applications built with Mastra
